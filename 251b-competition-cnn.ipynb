{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f091e88a-eba8-4354-8877-1e3dc8673dbd",
   "metadata": {},
   "source": [
    "# CSE 251B Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8be693-4904-4653-9e4c-97b174fddf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjerickson/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59ee05b-00cc-40e4-ab5f-7612fce1a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f4662d-5cd6-4236-ae84-3f616a9b2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205942\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " This notebook uses train as an example.\n",
    " Change to the val folder for evaluation \n",
    "\"\"\"\n",
    "\n",
    "train_path = \"./train/train\"\n",
    "val_path = \"./val_in/val_in\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_data  = ArgoverseDataset(data_path=train_path)\n",
    "val_data = ArgoverseDataset(data_path=val_path)\n",
    "print(len(train_data))\n",
    "print(len(val_data))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42330bb-f7ff-4734-86dc-e11cc04c4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = np.stack( inp, axis=0 )\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = np.stack( out, axis=0 )\n",
    "\n",
    "    inp = torch.LongTensor(inp).to(device)\n",
    "    out = torch.LongTensor(out).to(device)\n",
    "    return [inp, out]\n",
    "\n",
    "#train_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)\n",
    "\n",
    "# split_number = int(len(data_extracted)*0.8)\n",
    "# train_idx = [i for i in range(split_number)]\n",
    "# test_idx = [i+split_number for i in range(len(data)-split_number)]\n",
    "# train_sub = torch.utils.data.Subset(data_extracted, train_idx)\n",
    "# test_sub = torch.utils.data.Subset(data_extracted, test_idx)\n",
    "\n",
    "train_dataset = DataLoader(train_data,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)\n",
    "# test_dataset = DataLoader(val_data,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690bd7be-ed19-4e00-817a-b1484c370b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLDNNClassifier(\n",
       "  (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0)\n",
       "  (decoder): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (decoder2): AvgPool2d(kernel_size=(9, 1), stride=(9, 1), padding=0)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CLDNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLDNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(60, 60, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(60,60,3,padding=1)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.avgpool = nn.AvgPool2d((2,1))\n",
    "        #self.embedding = torch.nn.Embedding(num_embeddings = 65000, embedding_dim = 64)\n",
    "        #self.lstm = torch.nn.LSTM(input_size = 1, hidden_size = 6*30*4, num_layers = 1,\n",
    "        #                            batch_first = True, dropout = 0.2)\n",
    "        self.decoder = nn.Conv2d(60,60,1)\n",
    "        self.decoder2 = nn.AvgPool2d((9,1))\n",
    "        # as we have 5 classes\n",
    "        #self.linear = nn.Linear(8*2*512, 5) # last dimension\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.embedding(x)\n",
    "        #x = torch.reshape(x,[x.shape[0],64,1])\n",
    "        #print(x.shape)\n",
    "        #x, _ = self.lstm(x)\n",
    "        x = F.relu(self.decoder(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.decoder2(x))\n",
    "        #print(x.shape)\n",
    "        #x = self.linear(x.reshape(x.shape[0], -1))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# create our model\n",
    "\n",
    "lstm = CLDNNClassifier()\n",
    "lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ad75d5-6caa-44fd-9088-12e8063a23d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68580\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in lstm.parameters())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f34ef99-1281-41ff-a5e5-44beec9af385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 0, training loss: 92.05585\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 1, training loss: 99.73798\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 2, training loss: 122.78164\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 3, training loss: 107.32553\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 4, training loss: 61.49115\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 5, training loss: 421.19397\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 6, training loss: 73.58657\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 7, training loss: 792.46515\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 8, training loss: 664.55719\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "Epoch: 9, training loss: 82.20241\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "#input_size = 4\n",
    "#hidden_size = 2\n",
    "num_layers = 2\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "#lstm = nn.LSTM(input_size=(19,4), hidden_size=128, num_layers=2, proj_size=(30,4))\n",
    "\n",
    "criterion = torch.nn.MSELoss().to(device)    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i_batch, sample_batch in enumerate(train_dataset):\n",
    "        trainX, trainY = sample_batch\n",
    "        \n",
    "\n",
    "        #trainX = torch.reshape(trainX,(trainX.shape[0]*trainX.shape[1], trainX.shape[2], trainX.shape[3]))\n",
    "        trainX = trainX.float()\n",
    "\n",
    "        #trainY = torch.reshape(trainY,(trainY.shape[0]*trainY.shape[1], trainY.shape[2], trainY.shape[3]))\n",
    "        trainY = trainY.float()\n",
    "        \n",
    "        outputs = lstm(trainX)\n",
    "        \n",
    "        # if i_batch == 0:\n",
    "        #     print(outputs.size())\n",
    "        #     print(trainY.size())\n",
    "        optimizer.zero_grad()\n",
    "        #print(trainY.shape)\n",
    "        #print(trainY[:,:,0:1,:].shape)\n",
    "        # obtain the loss function\n",
    "        #print(outputs.shape)\n",
    "        #print(trainY.shape)\n",
    "        loss = criterion(outputs, trainY[:,:,0:1,:])\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        if i_batch %1000==0:\n",
    "            print(i_batch)\n",
    "    print(\"Epoch: %d, training loss: %1.5f\" % (epoch, loss.item()))\n",
    "      # total=0\n",
    "      # with torch.no_grad():\n",
    "      #     mean_squared_error = nn.MSELoss().to(device)\n",
    "      #     for i_batch, sample_batch in enumerate(test_dataset):\n",
    "      #         testX, testY = sample_batch\n",
    "      #         testX = testX.float().to(device)\n",
    "      #         #print(testX.is_cuda)\n",
    "      #         testY = testY.float().to(device)\n",
    "      #         # calculate outputs by running images through the network\n",
    "      #         outputs = lstm(testX)\n",
    "      #         #print(outputs.is_cuda)\n",
    "      #         #print(outputs.shape)\n",
    "      #         mse = mean_squared_error(outputs,testY[:,:,0:1,:])\n",
    "      #         #print(testY[:,:,0:1,:].shape)\n",
    "      #         #print(mse)\n",
    "      #         total += mse\n",
    "      #     print(\"Epoch: %d, val loss: %1.5f\" % (epoch, total/(i_batch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d072ee-d0ce-4264-8882-ce852079069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_test(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    #out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "\n",
    "    inp = torch.LongTensor(inp).to(device)\n",
    "    #out = torch.LongTensor(out).to(device)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75f7d9b1-320f-47e9-bc2d-28d395ac29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_970/4286149211.py:6: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp).to(device)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import copy\n",
    "\n",
    "f1 = open('./sample_submission.csv', newline='')\n",
    "f = open('./sample_submission1.csv', 'w')\n",
    "reader = csv.reader(f1)\n",
    "writer = csv.writer(f)\n",
    "row1 = next(reader)  # gets the first line\n",
    "writer.writerow(row1)\n",
    "f1.close()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i in range(len(val_data)):\n",
    "    all_data = torch.zeros([1,60,19+30,4],dtype=torch.float).to(device)\n",
    "    all_data[0,:,:19,:] = my_collate_test([val_data[i]])\n",
    "    #testX = my_collate_test([data_test[i]])\n",
    "    id = np.where(val_data[i]['track_id']==val_data[i]['agent_id'])[0][0]\n",
    "    data_to_csv = []\n",
    "    for j in range(30):\n",
    "    #testX = testX.float().to(device)\n",
    "    #print(testX.shape)\n",
    "      outputs = lstm(all_data[0:1,:,j:19+j,:])\n",
    "      #print(outputs.shape)\n",
    "      all_data[0,:,j+19:j+20,:]=outputs[0,:,:,:]\n",
    "      outputs = torch.squeeze(outputs[:,id,:,:2])\n",
    "      #print(outputs.shape)\n",
    "      data_to_csv.append(float(outputs[0].cpu().numpy()))\n",
    "      data_to_csv.append(float(outputs[1].cpu().numpy()))\n",
    "      #break\n",
    "      #print(outputs.shape)\n",
    "    #row = [data_test[i]['scene_idx']]+[(float(outputs[i,0].cpu().numpy()),float(outputs[i,1].cpu().numpy())) for i in range(len(outputs))]\n",
    "    # open the file in the write mode\n",
    "    # write a row to the csv file\n",
    "    assert len(data_to_csv)==60\n",
    "    row = [val_data[i]['scene_idx']]+data_to_csv\n",
    "    writer.writerow(row)\n",
    "    #break\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eab2224-cc2a-4acc-8401-4d0608600128",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), \"./weights.w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bbec3-cd2e-4543-b64a-688a944438d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
